pretrained_model_path: "./models/model_scope_diffusers/" #https://huggingface.co/damo-vilab/text-to-video-ms-1.7b/tree/main
output_dir: "./outputs"
train_text_encoder: False
offset_noise_strength: 0.1
use_offset_noise: True

train_data:
  json_path: "./json/train.json"
  preprocessed: True
  n_sample_frames: 2
  shuffle_frames: False
  width: 384      
  height: 256
  sample_start_idx: 0
  sample_frame_rate: 30
  vid_data_key: "video_path"

  single_video_path: ""
  single_video_prompt: ""

validation_data:
  prompt: ""
  sample_preview: True
  num_frames: 16
  width: 384
  height: 256
  num_inference_steps: 50
  guidance_scale: 9

learning_rate: 1e-5
adam_weight_decay: 1e-2
train_batch_size: 1
max_train_steps: 50000
checkpointing_steps: 5000
validation_steps: 100
trainable_modules:
  - "attn1"
  - "attn2"
  
  # Uncomment if you have ample VRAM.
  #- "temp_convs"
seed: 64
mixed_precision: "fp16"
use_8bit_adam: False # This seems to be incompatible at the moment. 

# Xformers must be installed
enable_xformers_memory_efficient_attention: True

# Use scaled dot product attention (Only available with >= Torch 2.0)
enable_torch_2_attn: True